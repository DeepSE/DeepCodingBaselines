# Guidance for the UROP program
This guidance provides high-level goals and plans for the UROP (Undergraduate Research Opportunities Program) project.

## Goals
  * Having fun and following your interest
  * Becoming an expert in an area
  * Strong implementation skills + theoretical background
  * Innovative industrial application ideas (optional)

## Plans
#### Practice -> Implementation -> Innovation/Application

1. Learn and practice on deep learning basics(e.g., CNN, RNN, Attention, etc).

2. Choose a baseline that you are interested in and try to implement it.

3. Think about new ideas to improve the model you are implementing [Optional]<br/>
or<br/>
Find some interesting applications (especially in the code mining domain). [Optional]


## Assignment
Zhao Zixuan \#16

Gao Tong and Fang Haoyang \#10

Vikram Sambamurthy \#4

Hou Kaijun \#17

## Baselines
Here we provide some popular baselines in our domain. They are about QA systems and deep language models or their applications in the code mining (deep coding) area. Each paper has links to the pdf/data/code. Please choose one you would like to implement. 
During implementing, please read related papers and keep track of the state-of-art techniques/results of the same topic.  
If you get any new ideas/thoughts/problems please discuss with Xiaodong Gu.

NOTE: If you find interesting papers other than the list and would like to implement, please propose and discuss with Xiaodong Gu.

1. \[Code Completion\] Code completion with statistical language models (PLDI 2014) 
   * Paper: [pdf](http://www.srl.inf.ethz.ch/papers/pldi14-statistical.pdf)
   * Code: [google drive](https://drive.google.com/file/d/0B0wMwmX05Ri7a056TllETHFEelU/view)
   
2. \[Code Completion\] Toward deep learning software repositories (MSR 2015)
   * Paper: [pdf](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.714.5031&rep=rep1&type=pdf)
   * Code: TBD
   
3. \[Dialogue\] Dual Encoder LSTM (SigDial 2015)
    * Paper: [arxiv](https://arxiv.org/abs/1506.08909)
    * Data: [ubuntu corpus](https://drive.google.com/open?id=0B_bZck-ksdkpVEtVc1R6Y01HMWM) 
    * Code: [chatbot-retrieval](https://github.com/dennybritz/chatbot-retrieval)
    * Tutorial:[chatbot-retrieval](http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/)
    
4. \[Dialogue\] Smart Reply: Automated Response Suggestion for Email (KDD_2016)
    * Paper: [pdf](https://github.com/DeepSE/DeepCodingBaselines/raw/master/papers/smart-reply.pdf)
    * Code: TBA
    * Results: ?
    * Notes: [gitgist:](https://gist.github.com/shagunsodhani/da411f15b71ed6a664f9d5ac46409b42)

5. \[Bug Localization\] Learning Unified Features from Natural and Programming Languages for Locating Buggy Source Code (IJCAI 2016)
    * Paper: [pdf](https://pdfs.semanticscholar.org/7848/5ab466e1a83e7965500cceab476b55d145c0.pdf)
    * Code: TBD  
    
6. \[Code Clone Detection\] Deep Learning Code Fragments for Code Clone Detection (ASE 2016)
    * Paper: [pdf](http://www.cs.wm.edu/~denys/pubs/ASE'16-DeepLearningClones.pdf)
    * Code: TBD
    
7. \[Code Summarization\] Summarizing Source Code using a Neural Attention Model (ACL 2016)
    * Paper: [pdf](https://www.aclweb.org/anthology/P/P16/P16-1195.pdf)
    * Data: [stack overflow](https://github.com/sriniiyer/codenn/tree/master/data/stackoverflow) 
    * Code: [github](https://github.com/sriniiyer/codenn)
    
8. \[Dialog\] Deep Reinforcement Learning for Dialogue Generation (EMNLP 2016)
    * Paper: [arxiv](https://arxiv.org/pdf/1606.01541.pdf)
    * Data:
    * Code:

9. \[Dialogue\] A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues (AAAI 2017)
    * Paper: [arxiv](https://arxiv.org/abs/1605.06069) 
    * Code: [github](https://github.com/julianser/hed-dlg-truncated) 

10. \[Dialogue\] Latent Variable Dialogue Models and their Diversity (EACL 2017) 
    * Paper: [arxiv](https://arxiv.org/abs/1702.05962)
    * Code: TBD

11. \[Dialogue\] Generating Long and Diverse Responses with Neural Conversation Models (ICLR 2017)
    * Paper: [arxiv](https://arxiv.org/abs/1701.03185)
    * Code: TBD

12. \[Dialogue\] Diverse Beam Search:Decoding Diverse Solutions from Neural Sequence Models (ICLR 2017)
    * Paper: [arxiv](https://arxiv.org/abs/1610.02424)
    * Code: [github](https://github.com/Cloud-CV/diverse-beam-search)

13. \[Code Completion\] Learning Python Code Suggestion with a Sparse Pointer Network (ICLR 2017 Submitted)
    * Paper: [Arxiv](https://arxiv.org/abs/1611.08307)
    * Code: [github](https://github.com/uclmr/pycodesuggest) 

14. \[Commit Summarization\] A Neural Architecture for Generating Natural Language Descriptions from Source Code Changes (ACL 2017)
    * Paper: [arxiv](https://arxiv.org/abs/1704.04856)
    * Data: [link](https://osf.io/67kyc/?view_only=ad588fe5d1a14dd795553fb4951b5bf9)
    * Code: [github](https://github.com/epochx/commitgen)
    
15. \[Bug Fix\] DeepFix- Fixing Common C Language Errors by Deep Learning (AAAI 2017)
    * Paper: [pdf](http://www.iisc-seal.net/publications/aaai17.pdf?attredirects=0&d=1)
    * Code: [projsite](http://www.iisc-seal.net/deepfix)
    
16. \[Overrun Detect\] End-to-End Prediction of Buffer Overruns from Raw Source Code via Neural Memory Networks (IJCAI 2017)
    * Paper:[arxiv](https://arxiv.org/pdf/1703.02458.pdf)
    * Data: [github](https://github.com/mjc92/buffer_overrun_memory_networks)
    * Code: TBD
    
17. \[GAN Text\] Adversarial Feature Matching for Text Generation (ICML 2017)
    * Paper:[arxiv](https://arxiv.org/pdf/1706.03850.pdf)


## Datasets

### QA - Retrieval
|No|Title|Paper|Blogs|Code|
|---|---|---|---|---|
|1|[Ubuntu Dialogue Corpus](https://drive.google.com/open?id=0B_bZck-ksdkpVEtVc1R6Y01HMWM)|[arxiv](https://arxiv.org/abs/1506.08909)|[Tutorial:chatbot-retrieval](http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/)|[ubottu](https://github.com/npow/ubottu)<br/> [corpus collector](https://github.com/rkadlec/ubuntu-ranking-dataset-creator)<br/> [chatbot-retrieval](https://github.com/dennybritz/chatbot-retrieval)|
|2|[OpenSubtitle](https://s3.amazonaws.com/opennmt-trainingdata/opensub_qa_en.tgz)|[arxiv](https://arxiv.org/pdf/1506.05869v3.pdf) | [Tutorial](http://forum.opennmt.net/t/english-chatbot-model-with-opennmt/184)<br/> [opensubtitle website](http://opus.lingfil.uu.se/OpenSubtitles.php)||
|3|[Twitter Corpus](http://homes.cs.washington.edu/~aritter/twitter_chat/)| [pdf](http://www.aclweb.org/anthology/N10-1020)|  |[corpus collector](https://github.com/bwbaugh/twitter-corpus)|

### QA - Encoder-Decoder

### QA - Comprehension
|No|Title|Paper|Blogs|Code|
|---|---|---|---|---|
|1|[SQuAD (Stanford QA Dataset)](https://rajpurkar.github.io/SQuAD-explorer)||||







